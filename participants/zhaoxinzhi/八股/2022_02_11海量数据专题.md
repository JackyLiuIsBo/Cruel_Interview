## 一、写在前面

今天总结下关于海量数据的题的一些模式、方法论的总结。

### 二、海量数据

> 参考链接：https://blog.csdn.net/v_july_v/article/details/7382693

### 1、何谓海量数据处理？

所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。

何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。

### 2、解决思路

针对时间，我们可以采用巧妙的算法搭配合适的数据结构，如Bloom filter/Hash/bit-map/堆/数据库或倒排索引/trie树；

针对空间，无非就一个办法：大而化小，分而治之（hash映射），你不是说规模太大嘛，那简单啊，就把规模大化为规模小的，各个击破不就完了嘛。

针对单机及集群问题，通俗点来讲，单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互)，而集群，机器有多辆，适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。

### 3、常用套路

分而治之/hash映射 + hash统计 + 堆/快速/归并排序；
双层桶划分
Bloom filter/Bitmap；
Trie树/数据库/倒排索引；
外排序；
分布式处理之Hadoop/Mapreduce。

### 4、实战举例

#### 例题1：海量日志数据，提取出某日访问百度次数最多的那个IP

> 解题套路：分而治之/hash映射 + hashmap统计 + 堆/快速/归并排序

首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如%1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP（可以采用hash_map对那1000个文件中的所有IP进行频率统计，然后依次找出各个文件中频率最大的那个IP）及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。

> 追问：
>
> Q1：什么是Hash映射呢？
>
> A1：为了便于计算机在有限的内存中处理big数据，从而通过一种映射散列的方式让数据均匀分布在对应的内存位置(**如大数据通过取余的方式映射成小数存放在内存中，或大文件映射成多个小文件**)，而这个映射散列方式便是我们通常所说的hash函数，设计的好的hash函数能让数据均匀分布而减少冲突。尽管数据映射到了另外一些不同的位置，但数据还是原来的数据，只是代替和表示这些原始数据的形式发生了变化而已。

#### 例题2：搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

> 解题套路1：hashmap统计 + 堆/快速/归并排序求TopK
>
> 解题套路2：Trie树统计+堆/快速/归并排序求TopK
>
> （注意因为此题数据规模较小，能一次性装入内存，因此不需要Hash映射了。）

此题虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去（300万个字符串没有重复，都是最大长度，那么最多占用内存3M*1K/4=0.75G。所以可以将所有字符串都存放在内存中进行处理），然后hashmap或者Trie统计，然后排序即可。



#### 例题3：有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词

> 解题套路：分而治之/hash映射 + hashmap/Trie统计 + 堆/快速/归并排序求TopK

因为此题文件很大，且内存受限。所以先进行hash映射：顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件（记为x0,x1,...x4999）中。这样每个文件大概是200k左右。**如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。**

取出出现频率最大的100个词（可以用含100个结点的最小堆）后，再把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并（类似于归并排序）的过程了。

> 这里考虑两种策略了：一种是每个文件都 统计后直接更新到最终的堆中维护Top100；另一种是每个文件先单独统计前100，然后这5000个前100再去更新最终的Top100.



#### 例题4：海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10

> 解题套路：

问题分析：此题由之前的单机问题升级到了集群问题。

**情况1：每个数据元素只出现在某同一台机器中。**

跟前几个问题一样简化为单机问题，单机统计完之后再合并统计即可。

**情况2：同一个元素重复出现在不同的电脑中**

方案1：遍历一遍所有数据，重新hash取模，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面所说的方法，**统计每台电脑中的TOP10**，继而综合100台电脑上的TOP10，找出最终的TOP10。

方案2：暴力求解，即**每台电脑中统计所有元素的出现次数**，然后再综合100台电脑上的统计，再取Top10。



#### 例题5：有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。

> 解题套路

hash映射：顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件（记为a0,a1,..a9）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。

找一台内存在2G左右的机器，对a0~a9分别统计所有query的出现次数，分别输出到另外10个文件(记为b0~b9)

对b0~b9这10个文件进行归并排序（内排序与外排序相结合）

一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用Trie/hash_map直接来统计每个query出现的次数，然后TopK就可以了。



#### 例题6：给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

> 解题套路：a和b的分而治之/hash映射 + 所有a的hashset标记 + 对应b的check

10亿字节是1G，所以每个文件的大小约为5G×64=320G。远远大于内存限制的4G，不可能将其完全加载到内存中处理。

对a文件每个记录进行hash，根据所取得的值将url分别存储到1000个小文件，(记为a0~a999)，这样每个小文件大约300MB。遍历文件b，采取和a相同的hash方式将url分别存储到1000小文件中（记为b0~b999)。这样hash后，相同url只可能在对应的小文件中，不对应的小文件不可能有相同的url。因此我们只要求出1000组小文件中相同的url即可。

把a的每一个小文件储存到hashset中，遍历对应的b的小文件，查看并统计即可。



#### 例题7：怎么在海量数据中找出重复次数最多的一个？

> 解题套路：老套路了。

先做hash映射为小文件，每个小文件中分别找最多的一个，然后再综合所有文件的再找最多的一个。

#### 例题8：上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据

因为10亿字节是1G，因此可以假定内存能存下。所以直接hash_map统计+堆求TopK即可。

#### 例题9：一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。

如果文件比较大，无法一次性读入内存，可以采用hash取模的方法，将大文件分解为多个小文件，对于单个小文件利用hash_map或者trie树统计出每个小文件中10个最常出现的词，然后再进行归并处理，找出最终的10个最常出现的词。

#### 例题10：1000万字符串，其中有些是重复的，需要把重复的全部去掉，保留没有重复的字符串。请怎么设计和实现？

还是先hash映射城小文件，再分别统计再综合。

#### 例题11：一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。  

同上，首先根据用hash并求模，将文件分解为多个小文件，对于单个文件利用上题的方法求出每个文件件中10个最常出现的词。然后再进行归并处理，找出最终的10个最常出现的词。



------

==多层划分的套路==

#### 例题12：2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。

> 解题套路：分而治之
>
> 有个不成文的套路：程序的可运行内存是4M左右，即2^24个bit。

有点像鸽巢原理，整数个数为2^32,也就是，我们可以将这2^32个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用2-bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。

2-bitmap：每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义

#### 例题13：5亿个int找它们的中位数

复杂度On。

需要做两遍统计，如果数据存在硬盘上，就需要读取2次。
方法同基数排序有些像，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。

第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0~k-1的区间里数字的数量sum应该<n/2（2.5亿），而k+1 - 65535的计数和也<n/2。

第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x / 65536) + 32768 = k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum = 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。

---------

==布隆过滤器==

Bloom Filter是一种空间效率很高的随机数据结构，它的原理是，当一个元素被加入集合时，通过K个Hash函数将这个元素映射成一个位阵列（Bit array）中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检索元素一定不在；如果都是1，则被检索元素**很可能**在。这就是布隆过滤器的基本思想。

适用范围：可以用来实现数据字典，进行数据的判重，或者集合求交集。适合用于允许一定容错率的场合。

对于**例题6：给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？**

就有了新的解决方案：

我们来计算下内存的占用，4G=2^32字节，大概是40亿*8大概是340亿个bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）

--------

==Bitmap位图==

#### 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？

> 注意计算的时候别再40亿*4！！！别把unsigned int是4个字节再乘进去了！！又没让你保存40亿个整数，而是保存40亿！所以直接40亿=2^32就好了。再/8，就是512MB。

用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。

#### 已知某个文件内包含一些电话号码，每个号码为8位数字，统计不同号码的个数。

8位最多99 999 999，大概需要99m个bit，大概10几m字节的内存即可。 （可以理解为从0-99 999 999的数字，每个数字对应一个Bit位，所以只需要99M个Bit==1.2MBytes，这样，就用了小小的1.2M左右的内存表示了所有的8位数的电话）

---------------

==倒排索引==

倒排索引一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。

一句话理解：正向索引是给定索引列，去查询索引值。倒排索引是，给定某索引值，去查询有哪些列有该值。

倒排索引常用于：文档检索系统，查询那些文件包含了某单词，比如常见的学术论文的关键字搜索。

```
　举例：
　以英文为例，下面是要被索引的文本：
    T0 = "it is what it is"
    T1 = "what is it"
    T2 = "it is a banana"
    我们就能得到下面的反向文件索引：
    "a":      {2}
    "banana": {2}
    "is":     {0, 1, 2}
    "it":     {0, 1, 2}
    "what":   {0, 1}
　检索的条件"what","is"和"it"将对应集合的交集。
```



#### 非常大的文件，装不进内存。每行一个int类型数据，现在要你随机取100个数。

> 准确的来说，应该是设计一种存储方案，使得我可以在4GB内存中存储>2^30个int类型数据（因为1个int4个B），并且可以随机的取出100个数来。

  我们发现上述这道题，无论是以上任何一种模式/方法都不好做，那有什么好的别的方法呢？我们可以看看：操作系统内存分页系统设计(说白了，就是映射+建索引)。

  Windows 2000使用基于分页机制的虚拟内存。每个进程有4GB的虚拟地址空间。基于分页机制，这4GB地址空间的一些部分被映射了物理内存，一些部分映射硬盘上的交换文 件，一些部分什么也没有映射。程序中使用的都是4GB地址空间中的虚拟地址。而访问物理内存，需要使用物理地址。 关于什么是物理地址和虚拟地址，请看：


- 物理地址 (physical address): 放在寻址总线上的地址。放在寻址总线上，如果是读，电路根据这个地址每位的值就将相应地址的物理内存中的数据放到数据总线中传输。如果是写，电路根据这个 地址每位的值就将相应地址的物理内存中放入数据总线上的内容。物理内存是以字节(8位)为单位编址的。 
- 虚拟地址 (virtual address): 4G虚拟地址空间中的地址，程序中使用的都是虚拟地址。 使用了分页机制之后，4G的地址空间被分成了固定大小的页，每一页或者被映射到物理内存，或者被映射到硬盘上的交换文件中，或者没有映射任何东西。对于一 般程序来说，4G的地址空间，只有一小部分映射了物理内存，大片大片的部分是没有映射任何东西。物理内存也被分页，来映射地址空间。对于32bit的 Win2k，页的大小是4K字节。CPU用来把虚拟地址转换成物理地址的信息存放在叫做页目录和页表的结构里。 

  物理内存分页，一个物理页的大小为4K字节，第0个物理页从物理地址 0x00000000 处开始。由于页的大小为4KB，就是0x1000字节，所以第1页从物理地址 0x00001000 处开始。第2页从物理地址 0x00002000 处开始。可以看到由于页的大小是4KB，所以只需要32bit的地址中高20bit来寻址物理页。 

  返回上面我们的题目：非常大的文件，装不进内存。每行一个int类型数据，现在要你随机取100个数。针对此题，我们可以借鉴上述操作系统中内存分页的设计方法，做出如下解决方案：

  操作系统中的方法，先生成4G的地址表，在把这个表划分为小的4M的小文件做个索引，二级索引。30位前十位表示第几个4M文件，后20位表示在这个4M文件的第几个，等等，基于key value来设计存储，用key来建索引。

  但如果现在只有10000个数，然后怎么去随机从这一万个数里面随机取100个数？请读者思考。

