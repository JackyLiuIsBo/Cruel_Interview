# 海量数据处理(二)

**Bloom filter/Bitmap**
- 适用于进行数据的判重，或者集合求交集
- 问题举例
    - 给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢？
        - 如果允许一定的错误率，可使用`bloom filter`

    - 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。
        - 采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可
    - 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？
        - frome oo，用位图/Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。

**trie树, 数据库索引, 倒排索引**
- trie树
    - 适用情况
        - 适用范围：数据量大，重复多，但是数据种类小可以放入内存
    - 问题举例
        - 寻找热门查询：查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。
        - 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。
        - 1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现？
        - 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词。其解决方法是：用trie树统计每个词出现的次数，时间复杂度是O(n*le)（le表示单词的平准长度），然后是找出出现最频繁的前10个词。

- 数据库索引
    - 适用范围：大数据量的增删改查
- 倒排索引(Inverted index)
    - 适用范围：搜索引擎，关键字查询

- 分布式处理之mapreduce

 MapReduce是一种计算模型，简单的说就是将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果（REDUCE）
- 适用范围：数据量大，但是数据种类小可以放入内存
- 基本原理及要点：将数据交给不同的机器去处理，数据划分，结果归约。
- 问题示例：
    - 计算大文件中word的出现次数
    - 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。
    - 一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到$N^2$个数的中数(median)？
        - 假设这些数为32位无符号整数。将$0-2^{32}$平均划分为N段，每段对应一个机器，将$N^2$个数分配每个机器上。从低位机器计算个数，当已计算个数和>$\frac{N^2}{2}$时，就在前一个机器上i找到第k大的数中位数，其中$k=\frac{N^2}{2}-preSum_{i-1}$