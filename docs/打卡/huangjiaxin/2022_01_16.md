# 消息队列(四)
**12.消息过期了如何处理**
- 分析原因
    - 消息队列都有消息生产消费速度监控。
    - 生产者发送变快。优化消费者代码(扩大并发，优化业务处理逻辑耗时)， 消费者扩容。
    - 消费者消费变慢。看看是否为消费线程卡住，是否为python消费者消费逻辑处理时间过程而无其他线程及时进行心跳同步(真实遭遇)
- 优化性能
    - 生产端
        - 只需要注意设置合适的并发和批量大小，就可以达到很好的发送性能。
        - 如果消息发送端是一个微服务，主要接受 RPC 请求处理在线业务，对时延要求高，就通过并发来提升发送性能。
        - 如果系统是一个离线分析系统，更适合批量发送
    - 消费端
        - 一定要保证消费端的消费性能要高于生产端的发送性能，这样的系统才能健康的持续运行。
        - 优化消费业务逻辑， 水平扩容，增加消费者并发
        - 在水平扩容时，必须同步扩容主题中的分区（也叫队列）数量，确保 Consumer 的实例数和分区数量是相等的。否则无效果，因为对于消费者来说，在每个分区上实际上只能支持单线程消费。

**13.消息队列存储方式**
- 分布式KV存储
    - 这类 MQ 一般会采用诸如 LevelDB 、RocksDB 和 Redis 来作为消息持久化的方式。由于分布式缓存的读写能力要优于 DB ，所以在对消息的读写能力要求都不是比较高的情况下，采用这种方式倒也不失为一种可以替代的设计方案。
- 文件系统
    - 目前业界较为常用的几款产品（RocketMQ / Kafka / RabbitMQ）均采用的是消息刷盘至所部署虚拟机/物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）
- 关系型数据库 DB
    - Apache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用 JDBC 的方式来做消息持久化，通过简单的 XML 配置信息即可实现JDBC消息存储。
    - 普通关系数据库有性能瓶颈，不适于作为高IO高性能消息队列的底层存储
**14.如何自己设计消息队列**
- 需了解技术的基本原理、核心组成部分、基本架构构成
- 首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

- 其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。

- 其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。

- 能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。

